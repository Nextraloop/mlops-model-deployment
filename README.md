# mlops-model-deployment
Complete MLOps workflow demonstrating data versioning, model training, experiment tracking, API deployment, CI/CD integration, and monitoring


## ğŸ“Œ Project Title
**End-to-End MLOps Pipeline: From Model Development to Deployment and Monitoring**

## ğŸ“„ Description
This project demonstrates a full MLOps workflow using the California Housing dataset. It includes data preprocessing, training models (Linear Regression & Decision Tree), tracking experiments with MLflow, serving predictions through a FastAPI-based REST API, Docker containerization, CI/CD using GitHub Actions, and logging incoming prediction requests.

---

## ğŸ“ Project Structure
```
project/
â”œâ”€â”€ .github/workflows/ci.yml         # CI/CD pipeline with GitHub Actions
â”œâ”€â”€ api/app.py                       # FastAPI app for predictions
â”œâ”€â”€ data/                            # Raw and processed data
â”‚   â””â”€â”€ raw/housing.csv
â”‚   â””â”€â”€ processed/housing_cleaned.csv
â”œâ”€â”€ logs/predictions.log             # Log of prediction requests
â”œâ”€â”€ models/best_model.pkl            # Trained and saved model
â”œâ”€â”€ notebooks/eda.ipynb              # EDA and visualization
â”œâ”€â”€ src/                             # Core scripts
â”‚   â”œâ”€â”€ data_preprocessing.py        # Preprocessing logic
â”‚   â”œâ”€â”€ train.py                     # Model training & MLflow tracking
â”‚   â”œâ”€â”€ evaluate.py                  # (Optional) Evaluation metrics
â”‚   â””â”€â”€ predict.py                   # Prediction helpers
â”œâ”€â”€ tests/test_api.py                # Unit test for API
â”œâ”€â”€ Dockerfile                       # Docker config for containerization
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ .gitignore                       # Files/folders to ignore in git
â””â”€â”€ deploy.sh                        # Shell script for deployment
```

---

## âš™ï¸ Features Implemented
- Data cleaning and scaling using `sklearn`
- Training multiple models and tracking them using `MLflow`
- Registering and saving the best-performing model
- REST API for predictions using `FastAPI`
- Dockerized API service
- Automated testing and linting with GitHub Actions
- CI/CD pipeline that builds and runs the container
- Logging prediction requests to a file

---

## ğŸš€ Getting Started

### Clone the repository
```bash
git clone https://github.com/your-username/mlops-housing-regression-pipeline.git
cd mlops-housing-regression-pipeline
```

### Install dependencies
```bash
pip install -r requirements.txt
```

### Train model
```bash
python src/train.py
```

### Run API locally
```bash
uvicorn api.app:app --reload
```

### Test API
```bash
curl -X POST http://127.0.0.1:8000/predict -H "Content-Type: application/json" \
     -d '{"features": [8.3252, 41, 6.9841, 1.0238, 322, 2.5556, 37.88, -122.23]}'
```

---

## ğŸ³ Docker
```bash
docker build -t mlops-api .
docker run -p 8000:8000 mlops-api
```

---

## ğŸ” CI/CD with GitHub Actions
- Code is automatically linted and tested on every push.
- Docker image is built and ready to be pushed/deployed.

---

## ğŸ“Š Logging and Monitoring
- Logs all API requests and responses to `logs/predictions.log`
- (Optional) Expose `/metrics` endpoint using Prometheus if needed.

---

## ğŸ“¦ Dataset
California Housing dataset: available via `sklearn.datasets.fetch_california_housing()` or `housing.csv` in `data/raw/`

---

## ğŸ‘¨â€ğŸ’» Author
**Your Name** (Add your GitHub or email)

---

## ğŸ“„ License
[MIT License](LICENSE) (Optional)

